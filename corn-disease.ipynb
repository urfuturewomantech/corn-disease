{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/KKhouma/fbd0b12f1456ea40224cde4180c24626/corn-disease.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L_SpjGleWB1L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import zip"
      ],
      "metadata": {
        "id": "5I-7ucdWb_vS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kodY8nEWiPe",
        "outputId": "63c6dc7c-77cb-4ec0-ae56-885400ffe186"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we use google colab and store the data in shared drive. different source will have different method\n",
        "# dont forget to mount drive first\n",
        "local_zip = '/content/drive/Shareddrives/Capstone C23-PC599/Machine Learning/corndisease.zip'\n",
        "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "A8wz9873ab6C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_path = '/tmp/jagung'\n",
        "\n",
        "source_path_bercak = os.path.join(source_path, 'bercak')\n",
        "source_path_hawar = os.path.join(source_path, 'hawar')\n",
        "source_path_karat = os.path.join(source_path, 'karat')\n",
        "source_path_sehat = os.path.join(source_path, 'sehat')\n",
        "\n",
        "\n",
        "print(f\"ada {len(os.listdir(source_path_bercak))} gambar bercak daun.\")\n",
        "print(f\"ada {len(os.listdir(source_path_hawar))} gambar hawar daun.\")\n",
        "print(f\"ada {len(os.listdir(source_path_karat))} gambar karat daun.\")\n",
        "print(f\"ada {len(os.listdir(source_path_sehat))} gambar daun sehat.\")\n"
      ],
      "metadata": {
        "id": "UaCeFD9xcC6w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "325a428e-5cd8-4f8e-a136-77bb69248332"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ada 513 gambar bercak daun.\n",
            "ada 985 gambar hawar daun.\n",
            "ada 1192 gambar karat daun.\n",
            "ada 1162 gambar daun sehat.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make directory for split training and validation"
      ],
      "metadata": {
        "id": "EX-lz2rMgIE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = '/tmp/corn_disease'\n",
        "\n",
        "if os.path.exists(root_dir):\n",
        "  shutil.rmtree(root_dir)\n",
        "\n",
        "def create_dir(root_path):\n",
        "  os.mkdir('/tmp/corn_disease')\n",
        "  os.mkdir('/tmp/corn_disease/training')\n",
        "  os.mkdir('/tmp/corn_disease/validation')\n",
        "  os.mkdir('/tmp/corn_disease/training/bercak')\n",
        "  os.mkdir('/tmp/corn_disease/training/hawar')\n",
        "  os.mkdir('/tmp/corn_disease/training/karat')\n",
        "  os.mkdir('/tmp/corn_disease/training/sehat')\n",
        "  os.mkdir('/tmp/corn_disease/validation/bercak')\n",
        "  os.mkdir('/tmp/corn_disease/validation/hawar')\n",
        "  os.mkdir('/tmp/corn_disease/validation/karat')\n",
        "  os.mkdir('/tmp/corn_disease/validation/sehat') \n",
        "\n",
        "try:\n",
        "  create_dir(root_path=root_dir)\n",
        "except FileExistsError:\n",
        "  print(\"direktori sudah ada\")"
      ],
      "metadata": {
        "id": "gM1IcIaNgMKY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for rootdir, dirs, files in os.walk(root_dir):\n",
        "    for subdir in dirs:\n",
        "        print(os.path.join(rootdir, subdir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6rKN-fVi9qx",
        "outputId": "ebcd9a69-3c61-4de7-8994-f3eeefd35e41"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/corn_disease/validation\n",
            "/tmp/corn_disease/training\n",
            "/tmp/corn_disease/validation/sehat\n",
            "/tmp/corn_disease/validation/bercak\n",
            "/tmp/corn_disease/validation/hawar\n",
            "/tmp/corn_disease/validation/karat\n",
            "/tmp/corn_disease/training/sehat\n",
            "/tmp/corn_disease/training/bercak\n",
            "/tmp/corn_disease/training/hawar\n",
            "/tmp/corn_disease/training/karat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Data"
      ],
      "metadata": {
        "id": "faGeDpK4jESx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(source_dir, training_dir, validation_dir, split_size):\n",
        "  files = []\n",
        "  for filename in os.listdir(source_dir):\n",
        "    file = source_dir + filename\n",
        "    if os.path.getsize(file) > 0:\n",
        "      files.append(filename)\n",
        "    else:\n",
        "      print(filename + 'is zero length, so ignoring.')\n",
        "      \n",
        "  training_length = int(len(files) * split_size)\n",
        "  validation_length = int(len(files) - training_length)\n",
        "  shuffled_set = random.sample(files, len(files))\n",
        "  training_set = shuffled_set[0:training_length]\n",
        "  validation_set = shuffled_set[:validation_length]\n",
        "\n",
        "  for filename in training_set:\n",
        "    this_file = source_dir + filename\n",
        "    destination = training_dir + filename\n",
        "    copyfile(this_file, destination)    \n",
        "\n",
        "  for filename in validation_set:\n",
        "    this_file = source_dir + filename\n",
        "    destination = validation_dir + filename\n",
        "    copyfile(this_file, destination)"
      ],
      "metadata": {
        "id": "PJ-0WXYWjGdg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#source file\n",
        "source_bercak_dir = \"/tmp/jagung/bercak/\"\n",
        "source_hawar_dir = \"/tmp/jagung/hawar/\"\n",
        "source_karat_dir = \"/tmp/jagung/karat/\"\n",
        "source_sehat_dir = \"/tmp/jagung/sehat/\"\n",
        "\n",
        "#define train and validation dir\n",
        "training_dir = \"/tmp/corn_disease/training\"\n",
        "validation_dir = \"/tmp/corn_disease/validation\"\n",
        "\n",
        "#define file bercak jagung\n",
        "training_bercak_dir = os.path.join(training_dir, \"bercak/\")\n",
        "validation_bercak_dir = os.path.join(validation_dir, \"bercak/\")\n",
        "\n",
        "#define file hawar jagung\n",
        "training_hawar_dir = os.path.join(training_dir, \"hawar/\")\n",
        "validation_hawar_dir = os.path.join(validation_dir, \"hawar/\")\n",
        "\n",
        "#define file karat jagung\n",
        "training_karat_dir = os.path.join(training_dir, \"karat/\")\n",
        "validation_karat_dir = os.path.join(validation_dir, \"karat/\")\n",
        "\n",
        "#define file jagung sehat\n",
        "training_sehat_dir = os.path.join(training_dir, \"sehat/\")\n",
        "validation_sehat_dir = os.path.join(validation_dir, \"sehat/\")\n",
        "\n",
        "# Empty directories in case you run this cell multiple times\n",
        "if len(os.listdir(training_bercak_dir)) > 0:\n",
        "  for file in os.scandir(training_bercak_dir):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(validation_bercak_dir)) > 0:\n",
        "  for file in os.scandir(validation_bercak_dir):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(training_hawar_dir)) > 0:\n",
        "  for file in os.scandir(training_hawar_dir):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(validation_hawar_dir)) > 0:\n",
        "  for file in os.scandir(validation_hawar_dir):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(training_karat_dir)) > 0:\n",
        "  for file in os.scandir(training_karat_dir):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(validation_karat_dir)) > 0:\n",
        "  for file in os.scandir(validation_karat_dir):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(training_sehat_dir)) > 0:\n",
        "  for file in os.scandir(training_sehat_dir):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(validation_sehat_dir)) > 0:\n",
        "  for file in os.scandir(validation_sehat_dir):\n",
        "    os.remove(file.path)\n",
        "# Define proportion of images used for training\n",
        "split_size = .9\n",
        "\n",
        "split_data(source_bercak_dir, training_bercak_dir, validation_bercak_dir, split_size)\n",
        "split_data(source_hawar_dir, training_hawar_dir, validation_hawar_dir, split_size)\n",
        "split_data(source_karat_dir, training_karat_dir, validation_karat_dir, split_size)\n",
        "split_data(source_sehat_dir, training_sehat_dir, validation_sehat_dir, split_size)\n",
        "\n",
        "# Your function should perform copies rather than moving images so original directories should contain unchanged images\n",
        "print(f\"\\n\\nOriginal bercak directory has {len(os.listdir(source_bercak_dir))} images\")\n",
        "print(f\"Original hawar directory has {len(os.listdir(source_hawar_dir))} images\")\n",
        "print(f\"Original karat directory has {len(os.listdir(source_karat_dir))} images\")\n",
        "print(f\"Original sehat directory has {len(os.listdir(source_sehat_dir))} images\\n\")\n",
        "\n",
        "print(f\"There are {len(os.listdir(training_bercak_dir))} images of bercak for training\")\n",
        "print(f\"There are {len(os.listdir(training_hawar_dir))} images of hawar for training\")\n",
        "print(f\"There are {len(os.listdir(training_karat_dir))} images of karat for training\")\n",
        "print(f\"There are {len(os.listdir(training_sehat_dir))} images of sehat for training\")\n",
        "print(f\"There are {len(os.listdir(validation_bercak_dir))} images of bercak for validation\")\n",
        "print(f\"There are {len(os.listdir(validation_hawar_dir))} images of hawar for validation\")\n",
        "print(f\"There are {len(os.listdir(validation_karat_dir))} images of karat for validation\")\n",
        "print(f\"There are {len(os.listdir(validation_sehat_dir))} images of sehat for validation\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMuVX-HEj33Y",
        "outputId": "09e9b0a7-697b-48d7-e58f-9aa9b72f6fb4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Original bercak directory has 513 images\n",
            "Original hawar directory has 985 images\n",
            "Original karat directory has 1192 images\n",
            "Original sehat directory has 1162 images\n",
            "\n",
            "There are 461 images of bercak for training\n",
            "There are 886 images of hawar for training\n",
            "There are 1072 images of karat for training\n",
            "There are 1045 images of sehat for training\n",
            "There are 52 images of bercak for validation\n",
            "There are 99 images of hawar for validation\n",
            "There are 120 images of karat for validation\n",
            "There are 117 images of sehat for validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"rohmankho@gmail.com\"\n",
        "!git config --global user.name \"KKhouma\""
      ],
      "metadata": {
        "id": "txLxfW1wXxHg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"# Machine-Learning-Model\" >> README.md\n",
        "!git init\n",
        "!git add README.md\n",
        "!git commit -m \"first commit\"\n",
        "!git branch -M main\n",
        "!git remote add origin git@github.com:KKhouma/CNN-corn-test-.git\n",
        "!git push -u origin main"
      ],
      "metadata": {
        "id": "wnktYVcHkO_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf470887-c8a3-4c60-e9d3-582b73c043ae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /content/.git/\n",
            "[main f23d5a8] first commit\n",
            " 1 file changed, 1 insertion(+)\n",
            "fatal: remote origin already exists.\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    }
  ]
}